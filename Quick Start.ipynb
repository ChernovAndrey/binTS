{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modeling import LightningBinConv\n",
    "from data import TSDataset, TSDatasetTest\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocessing import get_preprocessing_pipeline\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "            #Passengers\nMonth                  \n1949-01-01          112\n1949-02-01          118\n1949-03-01          132\n1949-04-01          129\n1949-05-01          121",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#Passengers</th>\n    </tr>\n    <tr>\n      <th>Month</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1949-01-01</th>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>1949-02-01</th>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>1949-03-01</th>\n      <td>132</td>\n    </tr>\n    <tr>\n      <th>1949-04-01</th>\n      <td>129</td>\n    </tr>\n    <tr>\n      <th>1949-05-01</th>\n      <td>121</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download toy dataset to validate the methods\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AileenNielsen/\"\n",
    "    \"TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "prediction_length = 12\n",
    "context_length = 12\n",
    "num_bins = 5000\n",
    "min_value = -3\n",
    "max_value = 3\n",
    "offset = -36 # for train/test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [
    "train_data = df.values[:offset]\n",
    "test_data = df.values[offset-context_length:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "pipeline = get_preprocessing_pipeline()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "net = LightningBinConv(\n",
    "    context_length=context_length,\n",
    "    num_bins=num_bins,\n",
    "    kernel_size_across_bins_2d=101,\n",
    "    kernel_size_across_bins_1d=101,\n",
    "    num_filters_2d= 8,\n",
    "    num_filters_1d= 32,\n",
    "    is_cum_sum = True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "dataset = TSDataset(data=train_data, context_length=context_length, scaler=pipeline)\n",
    "train_loader = DataLoader(dataset, batch_size=int(1e6), shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "data": {
      "text/plain": "LightningBinConv(\n  (conv): Conv2d(1, 8, kernel_size=(12, 101), stride=(1, 1))\n  (conv1d_1): Conv1d(8, 32, kernel_size=(101,), stride=(1,))\n  (conv1d_2): Conv1d(32, 1000, kernel_size=(101,), stride=(1,))\n)"
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type   | Params | Mode \n",
      "--------------------------------------------\n",
      "0 | conv     | Conv2d | 9.7 K  | train\n",
      "1 | conv1d_1 | Conv1d | 25.9 K | train\n",
      "2 | conv1d_2 | Conv1d | 3.2 M  | train\n",
      "--------------------------------------------\n",
      "3.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 M     Total params\n",
      "13.074    Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/andreichernov/miniforge3/envs/probts/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e2ef433bbb348079dd99a1f51edae87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6360, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(969.5607, device='mps:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(36.6321, device='mps:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(2.0905, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.7238, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.3883, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8685, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.3971, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.8349, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.7804, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.5967, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.3151, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.9678, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6406, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7478, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.1883, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.1299, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7276, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5939, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7392, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8765, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.9369, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.9143, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.8208, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6860, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5859, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6565, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7880, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7180, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5643, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5671, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6612, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.7150, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.6744, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.5573, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.4152, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.3524, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.3245, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2472, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2542, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2894, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2913, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.2496, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1867, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1574, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1719, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1362, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1404, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1448, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1322, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1100, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0957, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0966, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1008, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0975, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0935, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0962, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1020, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1067, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1095, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1103, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1093, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1070, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.1036, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0997, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0954, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0910, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0867, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0828, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0797, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0774, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0758, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0747, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0740, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0738, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0738, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0730, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0715, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0697, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0680, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0663, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0644, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0626, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0612, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0600, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0590, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0584, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0581, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0576, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0570, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0567, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0566, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0562, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0560, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0560, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0558, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0556, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0556, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0554, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0552, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0550, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0546, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0542, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0539, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0534, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0531, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0528, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0525, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0523, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0521, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0519, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0517, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0516, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0514, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0513, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0512, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0510, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0509, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0508, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0506, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0505, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0503, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0502, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0500, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0499, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0497, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0495, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0494, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0493, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0492, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0491, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0490, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0489, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0488, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0486, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0485, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0484, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0483, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0482, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0481, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0481, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0480, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0479, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0478, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0477, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0477, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0476, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0475, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0474, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0473, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0472, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0471, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0470, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0469, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0468, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0467, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0466, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0465, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0464, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0464, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0463, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0462, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0461, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0461, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0460, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0459, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0458, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(0.0458, device='mps:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=300)\n",
    "trainer.fit(net, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = TSDatasetTest(data=test_data, context_length=context_length, scaler=train_loader.dataset.scaler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(1e6),shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_sample = next(iter(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_sample.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#TODO: this is ugly, rewrite in future\n",
    "def extract_forecasts(pred_samples, window, context_length):\n",
    "    \"\"\"\n",
    "    Extracts and concatenates forecast windows from pred_samples.\n",
    "\n",
    "    Args:\n",
    "        pred_samples (np.ndarray): Array of prediction samples (e.g. [num_samples, forecast_len]).\n",
    "        window (int): Number of forecast windows to extract.\n",
    "        context_length (int): Number of context steps between each forecast start.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Concatenated forecast windows.\n",
    "    \"\"\"\n",
    "    indices = [(i * (context_length + 1)) for i in range(window)]\n",
    "    windows = [pred_samples[i][:context_length] for i in indices]\n",
    "    return np.concatenate(windows)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_samples = net.predict(test_sample, context_length)\n",
    "pred_samples = pipeline.inverse_transform(pred_samples.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred  = extract_forecasts(pred_samples, 3, context_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae = np.mean(np.abs(pred - test_data[context_length:]))\n",
    "print(f\"MAE: {mae:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(test_data[context_length:])\n",
    "plt.plot(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.predict(test_sample, context_length)[0][10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
